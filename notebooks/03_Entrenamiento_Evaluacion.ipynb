{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train/coches_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = df[[\"kms\", \"power\", \"antiquity\", \"doors\", \"num_make\"]]\n",
    "x = df.drop(columns=[\"make\", \"model\", \"version\", \"fuel\", \"shift\", \"color\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaler = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaler, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Lineal Regresion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20.114965379109844\n",
      "MAPE: 0.0005170942256873131\n",
      "MSE: 2523159.3856109506\n",
      "RMSE: 1588.4455878659962\n",
      "r2_score train 1.0\n",
      "r2_score test 0.9674993195340941\n"
     ]
    }
   ],
   "source": [
    "modelo_lr = LinearRegression()\n",
    "modelo_lr.fit(x_train, y_train)\n",
    "\n",
    "predictions = modelo_lr.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\n",
    "print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print(\"r2_score train\", modelo_lr.score(x_train, y_train))\n",
    "print(\"r2_score test\",modelo_lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_lr.pkl', \"wb\") as archivo:\n",
    "    pickle.dump(modelo_lr, archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Lineal Regresion con regresion polinomial de 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.2 GiB for an array with shape (31177, 125580) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\diego\\Desktop\\Proyecto_ML\\Proyecto-valor-coches-ML\\notebooks\\03_Entrenamiento_Evaluacion.ipynb Celda 12\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diego/Desktop/Proyecto_ML/Proyecto-valor-coches-ML/notebooks/03_Entrenamiento_Evaluacion.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m poly_feats \u001b[39m=\u001b[39m PolynomialFeatures(degree \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diego/Desktop/Proyecto_ML/Proyecto-valor-coches-ML/notebooks/03_Entrenamiento_Evaluacion.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m poly_feats\u001b[39m.\u001b[39mfit(x_scaler)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/diego/Desktop/Proyecto_ML/Proyecto-valor-coches-ML/notebooks/03_Entrenamiento_Evaluacion.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_poly \u001b[39m=\u001b[39m poly_feats\u001b[39m.\u001b[39;49mtransform(x_scaler)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diego/Desktop/Proyecto_ML/Proyecto-valor-coches-ML/notebooks/03_Entrenamiento_Evaluacion.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_poly,y, test_size \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/diego/Desktop/Proyecto_ML/Proyecto-valor-coches-ML/notebooks/03_Entrenamiento_Evaluacion.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lin_reg \u001b[39m=\u001b[39m LinearRegression()\n",
      "File \u001b[1;32mc:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:507\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    503\u001b[0m     XP \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mhstack(columns, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mtocsc()\n\u001b[0;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     \u001b[39m# Do as if _min_degree = 0 and cut down array after the\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[39m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m     XP \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    508\u001b[0m         shape\u001b[39m=\u001b[39m(n_samples, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_out_full), dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder\n\u001b[0;32m    509\u001b[0m     )\n\u001b[0;32m    511\u001b[0m     \u001b[39m# What follows is a faster implementation of:\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39m# for i, comb in enumerate(combinations):\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[39m#     XP[:, i] = X[:, comb].prod(1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m \n\u001b[0;32m    524\u001b[0m     \u001b[39m# degree 0 term\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 29.2 GiB for an array with shape (31177, 125580) and data type float64"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaler = scaler.fit_transform(x)\n",
    "\n",
    "poly_feats = PolynomialFeatures(degree = 3)\n",
    "poly_feats.fit(x_scaler)\n",
    "X_poly = poly_feats.transform(x_scaler)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_poly,y, test_size = 0.2, random_state=12)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train, y_train)\n",
    "\n",
    "predictions = lin_reg.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\n",
    "print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print(\"r2_score train\", lin_reg.score(x_train, y_train))\n",
    "print(\"r2_score test\",lin_reg.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_polinomial_regression.pkl', \"wb\") as archivo:\n",
    "    pickle.dump(modelo_lr, archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7148813341885825\n",
      "MAPE: 6.090478901409408e-05\n",
      "MSE: 30.001282873636946\n",
      "RMSE: 5.4773426836046095\n",
      "r2_score train 1.0\n",
      "r2_score test 0.9999996135550874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=20, random_state=42)\n",
    "tree_reg.fit(x_train, y_train)\n",
    "\n",
    "predictions = tree_reg.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\n",
    "print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print(\"r2_score train\", tree_reg.score(x_train, y_train))\n",
    "print(\"r2_score test\",tree_reg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_DecisionTreeRegressor.pkl', \"wb\") as archivo:\n",
    "    pickle.dump(modelo_lr, archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 833.4043724609793\n",
      "MAPE: 0.10643851722146545\n",
      "MSE: 2099369.5040802513\n",
      "RMSE: 1448.9201165282548\n",
      "r2_score train 0.9884059799346457\n",
      "r2_score test 0.9729581342260475\n"
     ]
    }
   ],
   "source": [
    "knn_reg = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "knn_reg.fit(x_train, y_train)\n",
    "\n",
    "predictions_knn = knn_reg.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions_knn))\n",
    "print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, predictions_knn))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, predictions_knn))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, predictions_knn)))\n",
    "print(\"r2_score train\", knn_reg.score(x_train, y_train))\n",
    "print(\"r2_score test\",knn_reg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_KNeighborsRegressor.pkl', \"wb\") as archivo:\n",
    "    pickle.dump(knn_reg, archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Pipeline (PCA y KNeighborsRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1482.5583707504811\n",
      "MAPE: 0.18589473994936484\n",
      "MSE: 6002104.013897799\n",
      "RMSE: 2449.9191851768906\n",
      "r2_score train 0.9601579733388461\n",
      "r2_score test 0.9226872207157101\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Paso de estandarización\n",
    "    ('pca', PCA(n_components=3)),  # Paso de reducción de dimensionalidad con PCA\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=3))  # Paso de clasificación con KNN\n",
    "])\n",
    "\n",
    "# Ajustamos el modelo en el conjunto de entrenamiento\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "prediciones_pipeline = pipeline.predict(x_test)\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, prediciones_pipeline))\n",
    "print(\"MAPE:\", metrics.mean_absolute_percentage_error(y_test, prediciones_pipeline))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, prediciones_pipeline))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, prediciones_pipeline)))\n",
    "print(\"r2_score train\", pipeline.score(x_train, y_train))\n",
    "print(\"r2_score test\",pipeline.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/modelo_Pipeline.pkl', \"wb\") as archivo:\n",
    "    pickle.dump(pipeline, archivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
